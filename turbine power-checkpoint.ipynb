{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3a8741-20c9-42ca-8921-92c1f87c7d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LinearRegression...\n",
      "Training DecisionTreeRegressor...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters for DecisionTreeRegressor: {'max_depth': 20, 'min_samples_split': 2}\n",
      "Training RandomForestRegressor...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters for RandomForestRegressor: {'max_depth': None, 'n_estimators': 200}\n",
      "Training KNeighborsRegressor...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters for KNeighborsRegressor: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "Training MLPRegressor...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters for MLPRegressor: {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "Training XGBRegressor...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters for XGBRegressor: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200}\n",
      "Training SVR...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best parameters for SVR: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Training GradientBoostingRegressor...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters for GradientBoostingRegressor: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200}\n",
      "\n",
      "Model Evaluation Results:\n",
      "LinearRegression:\n",
      "  R2 Score (%): 91.1518\n",
      "  MAE: 216.3237\n",
      "  RMSE: 256.9858\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "  R2 Score (%): 99.9880\n",
      "  MAE: 5.5997\n",
      "  RMSE: 9.4519\n",
      "\n",
      "RandomForestRegressor:\n",
      "  R2 Score (%): 99.9960\n",
      "  MAE: 3.0568\n",
      "  RMSE: 5.4664\n",
      "\n",
      "KNeighborsRegressor:\n",
      "  R2 Score (%): 98.8990\n",
      "  MAE: 59.1732\n",
      "  RMSE: 90.6511\n",
      "\n",
      "MLPRegressor:\n",
      "  R2 Score (%): 99.9997\n",
      "  MAE: 1.0964\n",
      "  RMSE: 1.5350\n",
      "\n",
      "XGBRegressor:\n",
      "  R2 Score (%): 99.9961\n",
      "  MAE: 3.6358\n",
      "  RMSE: 5.3609\n",
      "\n",
      "SVR:\n",
      "  R2 Score (%): 99.5466\n",
      "  MAE: 23.1244\n",
      "  RMSE: 58.1756\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  R2 Score (%): 99.9980\n",
      "  MAE: 2.5034\n",
      "  RMSE: 3.8801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "plt.style.use(\"Solarize_Light2\")  # using style ggplot\n",
    "%matplotlib inline\n",
    "\n",
    "# Load and prepare the data\n",
    "df = pd.read_csv('TexasTurbine_(3).csv')\n",
    "\n",
    "# Parse and clean datetime\n",
    "df['Time stamp'] = pd.to_datetime(df['Time stamp'], format='%b %d, %I:%M %p')\n",
    "df.set_index(\"Time stamp\", inplace=True)\n",
    "\n",
    "# Feature engineering (if necessary)\n",
    "df['Month'] = df.index.month\n",
    "\n",
    "X = df.drop(columns=\"System power generated | (kW)\")\n",
    "y = df[\"System power generated | (kW)\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "    \"KNeighborsRegressor\": KNeighborsRegressor(),\n",
    "    \"MLPRegressor\": MLPRegressor(max_iter=2000),\n",
    "    \"XGBRegressor\": XGBRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Define hyperparameters for GridSearchCV (example ranges, adjust as needed)\n",
    "param_grid = {\n",
    "    \"DecisionTreeRegressor\": {\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"RandomForestRegressor\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [None, 10, 20, 30]\n",
    "    },\n",
    "    \"KNeighborsRegressor\": {\n",
    "        \"n_neighbors\": [5, 10, 15],\n",
    "        \"weights\": ['uniform', 'distance']\n",
    "    },\n",
    "    \"MLPRegressor\": {\n",
    "        \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "        \"activation\": ['relu', 'tanh'],\n",
    "        \"solver\": ['adam']\n",
    "    },\n",
    "    \"XGBRegressor\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 6, 9]\n",
    "    },\n",
    "    \"SVR\": {\n",
    "        \"kernel\": ['linear', 'poly', 'rbf'],\n",
    "        \"C\": [1, 10, 100],\n",
    "        \"gamma\": ['scale', 'auto']\n",
    "    },\n",
    "    \"GradientBoostingRegressor\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"max_depth\": [3, 6, 9]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    try:\n",
    "        if name in param_grid:\n",
    "            grid_search = GridSearchCV(model, param_grid[name], cv=5, scoring='r2', n_jobs=-1, verbose=1)\n",
    "            grid_search.fit(X_train_scaled, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "        else:\n",
    "            best_model = model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_pred = best_model.predict(X_test_scaled)\n",
    "        \n",
    "        r2 = r2_score(y_test, y_pred) * 100\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "        results[name] = {\n",
    "            \"R2 Score (%)\": r2,\n",
    "            \"MAE\": mae,\n",
    "            \"RMSE\": rmse\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while training {name}: {e}\")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a136b-fe39-486e-9c61-494e28be19f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
